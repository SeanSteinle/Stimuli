{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all:\n",
    "\n",
    "this is my first attempt to do some data cleaning and preparation for our stimuli data in excel. bear with me, still new to a lot of the packages I'm using, but it ends up working pretty well.\n",
    "\n",
    "statistically relevant columns:\n",
    "(lets fill this out)\n",
    "\n",
    "resources:\n",
    "Penn Treebank Tags: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading excel doc into a Panda dataframe. this makes accessing the and mutating the code a lot easier to work with.\n",
    "\n",
    "(NaN means no value in the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Issue Issue Info Source   Category       Date First 2  Character Count  \\\n",
      "0      NaN        NaN   Kyra    Science 2020-09-18     Yes               10   \n",
      "1      NaN        NaN   Kyra    Opinion 2020-10-16     Yes               11   \n",
      "2      NaN        NaN  Mushi    Science 2020-11-26     Yes               12   \n",
      "3      NaN        NaN  Mushi   Business 2019-07-19     Yes               12   \n",
      "4      NaN        NaN  Mushi       U.S. 2019-01-30     Yes                9   \n",
      "..     ...        ...    ...        ...        ...     ...              ...   \n",
      "112    NaN        NaN   Kyra      World 2020-01-18     Yes               11   \n",
      "113    NaN        NaN   Kyra    Opinion 2020-01-18     Yes               12   \n",
      "114    NaN        NaN   Kyra    Opinion 2020-06-16     Yes               11   \n",
      "115    NaN        NaN   Kyra    Opinion 2020-06-12     Yes                9   \n",
      "116    NaN        NaN   Kyra  Parenting 2020-12-09     Yes                7   \n",
      "\n",
      "      Longest word  WC_Item  WC_S1  ...  Check - does WC_S1+WC_S2=WC_Item  \\\n",
      "0      reinforced.       27     17  ...                                OK   \n",
      "1     information.       30     12  ...                                OK   \n",
      "2    partnerships.       23     11  ...                                OK   \n",
      "3     presidential       30     19  ...                                OK   \n",
      "4        lawmakers       16     10  ...                                OK   \n",
      "..             ...      ...    ...  ...                               ...   \n",
      "112   storefronts.       35     11  ...                                OK   \n",
      "113   relationship       26     11  ...                                OK   \n",
      "114    experienced       34     11  ...                                OK   \n",
      "115      reflected       19      7  ...                                OK   \n",
      "116       breathe.       15      8  ...                                OK   \n",
      "\n",
      "                                                    S1  \\\n",
      "0    Men have a far greater appetite for sex and ar...   \n",
      "1    In the right hands, location data can be a for...   \n",
      "2    Male field crickets perform mating songs and d...   \n",
      "3    Paying for college seems out of reach for many...   \n",
      "4    Very few issues can bring together lawmakers o...   \n",
      "..                                                 ...   \n",
      "112  For the rural firefighters of Australia, no do...   \n",
      "113  Our relationship to privacy is inseparable fro...   \n",
      "114  Businesses do themselves a disservice by shyin...   \n",
      "115                 Earth is warming, and we know why.   \n",
      "116       Nobody ever really tells you how to breathe.   \n",
      "\n",
      "                                                    S2  \\\n",
      "0    This is the timeworn stereotype that science h...   \n",
      "1    It can provide publishers and app developers w...   \n",
      "2    Female Japanese macaque monkeys pair off into ...   \n",
      "3    Several Democratic presidential candidates and...   \n",
      "4                       Animal cruelty is one of them.   \n",
      "..                                                 ...   \n",
      "112  They have long been known to canvass for dolla...   \n",
      "113  If you trust someone, you may be more willing ...   \n",
      "114  Rather than worrying about only the potential ...   \n",
      "115  Light is reflected and absorbed by clouds, air...   \n",
      "116                        You just know how to do it.   \n",
      "\n",
      "                                  CompQ - True Version  \\\n",
      "0    Science has reinforced the stereotype that men...   \n",
      "1    Location data can be used to generate advertis...   \n",
      "2    The animals have relationships with their same...   \n",
      "3    Free college has been endorsed by several Demo...   \n",
      "4    Lawmakers are united on the issue of animal cr...   \n",
      "..                                                 ...   \n",
      "112  Rural Australian firefighters are known to can...   \n",
      "113                                                NaN   \n",
      "114  Companies do not realize the potential benefit...   \n",
      "115  The Earth is warming due to the constant refle...   \n",
      "116            Nobody has to be taught how to breathe.   \n",
      "\n",
      "                                 CompQ - False Version CompR  \\\n",
      "0    Science has reinforced a stereotype that women...   0.0   \n",
      "1    Location data cannot be used for anything that...   1.0   \n",
      "2    The monkeys perform mating songs and dances fo...   NaN   \n",
      "3    Free college has been endorsed by several Repu...   1.0   \n",
      "4    Lawmakers often disagree on the issue of anima...   NaN   \n",
      "..                                                 ...   ...   \n",
      "112                                                NaN   NaN   \n",
      "113  Our relationships with privacy and trust are s...   NaN   \n",
      "114  Companies worry about the cost of hiring young...   NaN   \n",
      "115               Light cannot be absorbed by the air.   NaN   \n",
      "116                  People must learn how to breathe.   NaN   \n",
      "\n",
      "                                           CompQ Notes  \\\n",
      "0                                                  NaN   \n",
      "1                                                  NaN   \n",
      "2    Difficult to incorporate both sentences into t...   \n",
      "3                                         Too obvious?   \n",
      "4                                                  NaN   \n",
      "..                                                 ...   \n",
      "112                                                NaN   \n",
      "113                                                NaN   \n",
      "114                                                NaN   \n",
      "115                                                NaN   \n",
      "116                                                NaN   \n",
      "\n",
      "                                    CompQ thoughts-Max ORDER  \\\n",
      "0                                                 Good   2.0   \n",
      "1                                                 Good   9.0   \n",
      "2         Needs COMPQ, previously filtered incorrectly  14.0   \n",
      "3    Both are true, just only 1 is mentioned by the...  19.0   \n",
      "4         Needs COMPQ, previously filtered incorrectly  20.0   \n",
      "..                                                 ...   ...   \n",
      "112                              Needs CompQ, new item   NaN   \n",
      "113                              Needs CompQ, new item   NaN   \n",
      "114                              Needs CompQ, new item   NaN   \n",
      "115                              Needs CompQ, new item   NaN   \n",
      "116                              Needs CompQ, new item   NaN   \n",
      "\n",
      "     Cassie's Comments  \n",
      "0                 good  \n",
      "1                 good  \n",
      "2                  NaN  \n",
      "3                 good  \n",
      "4                  NaN  \n",
      "..                 ...  \n",
      "112                NaN  \n",
      "113                NaN  \n",
      "114                NaN  \n",
      "115                NaN  \n",
      "116                NaN  \n",
      "\n",
      "[117 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "stimuli_sheet = pd.read_excel('Stimuli.xlsx')\n",
    "print(stimuli_sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first and second sentence column (S1 and S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Sentences: \n",
      " 0      Men have a far greater appetite for sex and ar...\n",
      "1      In the right hands, location data can be a for...\n",
      "2      Male field crickets perform mating songs and d...\n",
      "3      Paying for college seems out of reach for many...\n",
      "4      Very few issues can bring together lawmakers o...\n",
      "                             ...                        \n",
      "112    For the rural firefighters of Australia, no do...\n",
      "113    Our relationship to privacy is inseparable fro...\n",
      "114    Businesses do themselves a disservice by shyin...\n",
      "115                   Earth is warming, and we know why.\n",
      "116         Nobody ever really tells you how to breathe.\n",
      "Name: S1, Length: 117, dtype: object \n",
      "\n",
      "Second Sentences: \n",
      " 0      This is the timeworn stereotype that science h...\n",
      "1      It can provide publishers and app developers w...\n",
      "2      Female Japanese macaque monkeys pair off into ...\n",
      "3      Several Democratic presidential candidates and...\n",
      "4                         Animal cruelty is one of them.\n",
      "                             ...                        \n",
      "112    They have long been known to canvass for dolla...\n",
      "113    If you trust someone, you may be more willing ...\n",
      "114    Rather than worrying about only the potential ...\n",
      "115    Light is reflected and absorbed by clouds, air...\n",
      "116                          You just know how to do it.\n",
      "Name: S2, Length: 117, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"First Sentences: \\n\", stimuli_sheet.S1, \"\\n\\nSecond Sentences: \\n\",stimuli_sheet.S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is opening up the tagger object I hastily trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_load = open(\"Stanford_POS.pkl\",\"rb\")\n",
    "tagger = pickle.load(pickle_load)\n",
    "pickle_load.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaded a few sentences into a list, tokenized them with NLTK, tagged them with my tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Men', 'NNS'), ('have', 'VBP'), ('a', 'DT'), ('far', 'RB'), ('greater', 'JJR'), ('appetite', 'NN'), ('for', 'IN'), ('sex', 'NN'), ('and', 'CC'), ('are', 'VBP'), ('more', 'RBR'), ('attracted', 'VBN'), ('to', 'TO'), ('pornography', 'NN'), ('than', 'IN'), ('women', 'NNS'), ('are', 'VBP'), ('.', '.')]\n",
      "[('In', 'IN'), ('the', 'DT'), ('right', 'JJ'), ('hands', 'NNS'), (',', ','), ('location', 'NN'), ('data', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('a', 'DT'), ('force', 'NN'), ('for', 'IN'), ('good', 'NN'), ('.', '.')]\n",
      "[('Male', 'JJ'), ('field', 'NN'), ('crickets', 'NNS'), ('perform', 'VBP'), ('mating', 'VBG'), ('songs', 'NNS'), ('and', 'CC'), ('dances', 'NNS'), ('for', 'IN'), ('each', 'DT'), ('other', 'JJ'), ('.', '.')]\n",
      "[('Paying', 'VBG'), ('for', 'IN'), ('college', 'NN'), ('seems', 'VBZ'), ('out', 'IN'), ('of', 'IN'), ('reach', 'NN'), ('for', 'IN'), ('many', 'JJ'), ('Americans', 'NNPS'), (',', ','), ('so', 'IN'), ('the', 'DT'), ('idea', 'NN'), ('of', 'IN'), ('free', 'JJ'), ('college', 'NN'), ('has', 'VBZ'), ('broad', 'JJ'), ('appeal', 'NN'), ('.', '.')]\n",
      "[('Very', 'RB'), ('few', 'JJ'), ('issues', 'NNS'), ('can', 'MD'), ('bring', 'VB'), ('together', 'RB'), ('lawmakers', 'NNS'), ('of', 'IN'), ('both', 'DT'), ('parties', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "first_sents = stimuli_sheet['S1']\n",
    "play_sents = []\n",
    "play_sents = first_sents[:5]\n",
    "\n",
    "play_tokenized = []\n",
    "\n",
    "for sent in play_sents:\n",
    "    play_tokenized.append(nltk.word_tokenize(sent))\n",
    "for sent in play_tokenized:\n",
    "    print(tagger.tag(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets tag the whole thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ten', 'CD'), ('years', 'NNS'), ('ago', 'RB'), (',', ','), ('checklists', 'NNS'), ('for', 'IN'), ('surgeons', 'NNS'), ('were', 'VBD'), ('all', 'PDT'), ('the', 'DT'), ('rage', 'NN'), ('.', '.')]\n",
      "\n",
      "[('Inspired', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('preflight', 'JJ'), ('routines', 'NNS'), ('of', 'IN'), ('airline', 'NN'), ('pilots', 'NNS'), (',', ','), ('surgical', 'JJ'), ('checklists', 'NNS'), ('were', 'VBD'), ('shown', 'VBN'), ('to', 'TO'), ('prevent', 'VB'), ('tragic', 'JJ'), ('errors', 'NNS'), (',', ','), ('reduce', 'VB'), ('infections', 'NNS'), ('and', 'CC'), ('save', 'VB'), ('lives', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "s1_tokens = [] #list of word tokens from the first sentences\n",
    "s1_tagged = [] #list of tagged word tokens from the first sentences\n",
    "\n",
    "for sent in first_sents: #filling s1_tokens\n",
    "    s1_tokens.append(nltk.word_tokenize(sent))\n",
    "for sent in s1_tokens: #filling s1_tagged\n",
    "    s1_tagged.append(tagger.tag(sent))\n",
    "print(s1_tagged[101]) #sample output\n",
    "\n",
    "print()\n",
    "#doing the exact same thing for the second sentences\n",
    "second_sents = stimuli_sheet['S2']\n",
    "s2_tokens = [] #list of word tokens from the second sentences\n",
    "s2_tagged = [] #list of tagged word tokens from the second sentences\n",
    "\n",
    "for sent in second_sents: #filling s2_tokens\n",
    "    s2_tokens.append(nltk.word_tokenize(sent))\n",
    "for sent in s2_tokens: #filling s2_tagged\n",
    "    s2_tagged.append(tagger.tag(sent))\n",
    "print(s2_tagged[101]) #sample output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets get tags only (for syntactic surprisal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EX', 'VBD', 'DT', 'NN', 'VBG', 'RB', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'JJ', 'TO', 'DT', 'JJ', 'JJ', 'NN', '.']\n",
      "['PRP', 'VBD', 'VBG', 'RB', 'IN', 'DT', 'NN', ',', 'DT', 'JJ', 'NN', 'IN', 'NN', 'IN', 'PRP', '.']\n"
     ]
    }
   ],
   "source": [
    "s1_tags = [] #this will hold all of the tags\n",
    "for sent in s1_tagged: #filling s1_tags\n",
    "    s1_tags.append([(y) for (x,y) in sent])\n",
    "print(s1_tags[94]) #sample\n",
    "\n",
    "#same for s2\n",
    "s2_tags = [] #this will hold all of the tags\n",
    "for sent in s2_tagged: #filling s1_tags\n",
    "    s2_tags.append([(y) for (x,y) in sent])\n",
    "print(s2_tags[94]) #sample\n",
    "\n",
    "#renaming things for clarity:\n",
    "s1_both = s1_tagged\n",
    "s2_both = s1_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "great! so now we have three objects:\n",
    "\n",
    "s1_tokens/s2_tokens: a list of the words in the sentences\n",
    "s1_tags/s2_tags: a list of the tags in the sentences\n",
    "s1_both/s2_both: a list of both the words and the tags in the sentences (x,y)\n",
    "^see why I renamed this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue</th>\n",
       "      <th>Issue Info</th>\n",
       "      <th>Source</th>\n",
       "      <th>Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>First 2</th>\n",
       "      <th>Character Count</th>\n",
       "      <th>Longest word</th>\n",
       "      <th>WC_Item</th>\n",
       "      <th>WC_S1</th>\n",
       "      <th>...</th>\n",
       "      <th>Check - does WC_S1+WC_S2=WC_Item</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>CompQ - True Version</th>\n",
       "      <th>CompQ - False Version</th>\n",
       "      <th>CompR</th>\n",
       "      <th>CompQ Notes</th>\n",
       "      <th>CompQ thoughts-Max</th>\n",
       "      <th>ORDER</th>\n",
       "      <th>Cassie's Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyra</td>\n",
       "      <td>Science</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10</td>\n",
       "      <td>reinforced.</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>Men have a far greater appetite for sex and ar...</td>\n",
       "      <td>This is the timeworn stereotype that science h...</td>\n",
       "      <td>Science has reinforced the stereotype that men...</td>\n",
       "      <td>Science has reinforced a stereotype that women...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>2.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyra</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>information.</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>In the right hands, location data can be a for...</td>\n",
       "      <td>It can provide publishers and app developers w...</td>\n",
       "      <td>Location data can be used to generate advertis...</td>\n",
       "      <td>Location data cannot be used for anything that...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good</td>\n",
       "      <td>9.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mushi</td>\n",
       "      <td>Science</td>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12</td>\n",
       "      <td>partnerships.</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>Male field crickets perform mating songs and d...</td>\n",
       "      <td>Female Japanese macaque monkeys pair off into ...</td>\n",
       "      <td>The animals have relationships with their same...</td>\n",
       "      <td>The monkeys perform mating songs and dances fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Difficult to incorporate both sentences into t...</td>\n",
       "      <td>Needs COMPQ, previously filtered incorrectly</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mushi</td>\n",
       "      <td>Business</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12</td>\n",
       "      <td>presidential</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>Paying for college seems out of reach for many...</td>\n",
       "      <td>Several Democratic presidential candidates and...</td>\n",
       "      <td>Free college has been endorsed by several Demo...</td>\n",
       "      <td>Free college has been endorsed by several Repu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Too obvious?</td>\n",
       "      <td>Both are true, just only 1 is mentioned by the...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mushi</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>lawmakers</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>Very few issues can bring together lawmakers o...</td>\n",
       "      <td>Animal cruelty is one of them.</td>\n",
       "      <td>Lawmakers are united on the issue of animal cr...</td>\n",
       "      <td>Lawmakers often disagree on the issue of anima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Needs COMPQ, previously filtered incorrectly</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyra</td>\n",
       "      <td>World</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>storefronts.</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>For the rural firefighters of Australia, no do...</td>\n",
       "      <td>They have long been known to canvass for dolla...</td>\n",
       "      <td>Rural Australian firefighters are known to can...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Needs CompQ, new item</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyra</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12</td>\n",
       "      <td>relationship</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>Our relationship to privacy is inseparable fro...</td>\n",
       "      <td>If you trust someone, you may be more willing ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our relationships with privacy and trust are s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Needs CompQ, new item</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyra</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>experienced</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>Businesses do themselves a disservice by shyin...</td>\n",
       "      <td>Rather than worrying about only the potential ...</td>\n",
       "      <td>Companies do not realize the potential benefit...</td>\n",
       "      <td>Companies worry about the cost of hiring young...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Needs CompQ, new item</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyra</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>2020-06-12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>reflected</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>Earth is warming, and we know why.</td>\n",
       "      <td>Light is reflected and absorbed by clouds, air...</td>\n",
       "      <td>The Earth is warming due to the constant refle...</td>\n",
       "      <td>Light cannot be absorbed by the air.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Needs CompQ, new item</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kyra</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>breathe.</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>Nobody ever really tells you how to breathe.</td>\n",
       "      <td>You just know how to do it.</td>\n",
       "      <td>Nobody has to be taught how to breathe.</td>\n",
       "      <td>People must learn how to breathe.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Needs CompQ, new item</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Issue Issue Info Source   Category       Date First 2  Character Count  \\\n",
       "0      NaN        NaN   Kyra    Science 2020-09-18     Yes               10   \n",
       "1      NaN        NaN   Kyra    Opinion 2020-10-16     Yes               11   \n",
       "2      NaN        NaN  Mushi    Science 2020-11-26     Yes               12   \n",
       "3      NaN        NaN  Mushi   Business 2019-07-19     Yes               12   \n",
       "4      NaN        NaN  Mushi       U.S. 2019-01-30     Yes                9   \n",
       "..     ...        ...    ...        ...        ...     ...              ...   \n",
       "112    NaN        NaN   Kyra      World 2020-01-18     Yes               11   \n",
       "113    NaN        NaN   Kyra    Opinion 2020-01-18     Yes               12   \n",
       "114    NaN        NaN   Kyra    Opinion 2020-06-16     Yes               11   \n",
       "115    NaN        NaN   Kyra    Opinion 2020-06-12     Yes                9   \n",
       "116    NaN        NaN   Kyra  Parenting 2020-12-09     Yes                7   \n",
       "\n",
       "      Longest word  WC_Item  WC_S1  ...  Check - does WC_S1+WC_S2=WC_Item  \\\n",
       "0      reinforced.       27     17  ...                                OK   \n",
       "1     information.       30     12  ...                                OK   \n",
       "2    partnerships.       23     11  ...                                OK   \n",
       "3     presidential       30     19  ...                                OK   \n",
       "4        lawmakers       16     10  ...                                OK   \n",
       "..             ...      ...    ...  ...                               ...   \n",
       "112   storefronts.       35     11  ...                                OK   \n",
       "113   relationship       26     11  ...                                OK   \n",
       "114    experienced       34     11  ...                                OK   \n",
       "115      reflected       19      7  ...                                OK   \n",
       "116       breathe.       15      8  ...                                OK   \n",
       "\n",
       "                                                    S1  \\\n",
       "0    Men have a far greater appetite for sex and ar...   \n",
       "1    In the right hands, location data can be a for...   \n",
       "2    Male field crickets perform mating songs and d...   \n",
       "3    Paying for college seems out of reach for many...   \n",
       "4    Very few issues can bring together lawmakers o...   \n",
       "..                                                 ...   \n",
       "112  For the rural firefighters of Australia, no do...   \n",
       "113  Our relationship to privacy is inseparable fro...   \n",
       "114  Businesses do themselves a disservice by shyin...   \n",
       "115                 Earth is warming, and we know why.   \n",
       "116       Nobody ever really tells you how to breathe.   \n",
       "\n",
       "                                                    S2  \\\n",
       "0    This is the timeworn stereotype that science h...   \n",
       "1    It can provide publishers and app developers w...   \n",
       "2    Female Japanese macaque monkeys pair off into ...   \n",
       "3    Several Democratic presidential candidates and...   \n",
       "4                       Animal cruelty is one of them.   \n",
       "..                                                 ...   \n",
       "112  They have long been known to canvass for dolla...   \n",
       "113  If you trust someone, you may be more willing ...   \n",
       "114  Rather than worrying about only the potential ...   \n",
       "115  Light is reflected and absorbed by clouds, air...   \n",
       "116                        You just know how to do it.   \n",
       "\n",
       "                                  CompQ - True Version  \\\n",
       "0    Science has reinforced the stereotype that men...   \n",
       "1    Location data can be used to generate advertis...   \n",
       "2    The animals have relationships with their same...   \n",
       "3    Free college has been endorsed by several Demo...   \n",
       "4    Lawmakers are united on the issue of animal cr...   \n",
       "..                                                 ...   \n",
       "112  Rural Australian firefighters are known to can...   \n",
       "113                                                NaN   \n",
       "114  Companies do not realize the potential benefit...   \n",
       "115  The Earth is warming due to the constant refle...   \n",
       "116            Nobody has to be taught how to breathe.   \n",
       "\n",
       "                                 CompQ - False Version CompR  \\\n",
       "0    Science has reinforced a stereotype that women...   0.0   \n",
       "1    Location data cannot be used for anything that...   1.0   \n",
       "2    The monkeys perform mating songs and dances fo...   NaN   \n",
       "3    Free college has been endorsed by several Repu...   1.0   \n",
       "4    Lawmakers often disagree on the issue of anima...   NaN   \n",
       "..                                                 ...   ...   \n",
       "112                                                NaN   NaN   \n",
       "113  Our relationships with privacy and trust are s...   NaN   \n",
       "114  Companies worry about the cost of hiring young...   NaN   \n",
       "115               Light cannot be absorbed by the air.   NaN   \n",
       "116                  People must learn how to breathe.   NaN   \n",
       "\n",
       "                                           CompQ Notes  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    Difficult to incorporate both sentences into t...   \n",
       "3                                         Too obvious?   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "112                                                NaN   \n",
       "113                                                NaN   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "\n",
       "                                    CompQ thoughts-Max ORDER  \\\n",
       "0                                                 Good   2.0   \n",
       "1                                                 Good   9.0   \n",
       "2         Needs COMPQ, previously filtered incorrectly  14.0   \n",
       "3    Both are true, just only 1 is mentioned by the...  19.0   \n",
       "4         Needs COMPQ, previously filtered incorrectly  20.0   \n",
       "..                                                 ...   ...   \n",
       "112                              Needs CompQ, new item   NaN   \n",
       "113                              Needs CompQ, new item   NaN   \n",
       "114                              Needs CompQ, new item   NaN   \n",
       "115                              Needs CompQ, new item   NaN   \n",
       "116                              Needs CompQ, new item   NaN   \n",
       "\n",
       "     Cassie's Comments  \n",
       "0                 good  \n",
       "1                 good  \n",
       "2                  NaN  \n",
       "3                 good  \n",
       "4                  NaN  \n",
       "..                 ...  \n",
       "112                NaN  \n",
       "113                NaN  \n",
       "114                NaN  \n",
       "115                NaN  \n",
       "116                NaN  \n",
       "\n",
       "[117 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimuli_sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets store these objects into a new, less cluttered DF.\n",
    "what are some of the columns in Stimuli.xlsx that we might find useful?\n",
    "character count, WC_S1, WC_S2, S1, S2, tokenized S1, tokenized S2, tagged S1, tagged S2, tags-only S1, tags-only S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-37e7cbaabdf5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-37e7cbaabdf5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    stim_pd =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stim_pd = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
