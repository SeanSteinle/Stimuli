{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprisal Models\n",
    "**Brief**:<br>\n",
    "This will be the main file for all of our model loading, data organizing, searching, etc.\n",
    "**Sections**:\n",
    "1. [Starting A StanfordCoreNLP Server](#1)\n",
    "    - [Background](#1_a)\n",
    "    - [How To Run The Server](#1_b)\n",
    "    - [Resources](#1_c)\n",
    "    - [Code](#1_d)\n",
    "2. [Applying Models](#2)\n",
    "___\n",
    "<a id='1'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting A StanfordCoreNLP Server\n",
    "<a id='1_a'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background**:<br>\n",
    "We've spent a lot of time looking at the StanfordCoreNLP software, and we ultimately decided we want to use both the parser and tagger (really, the parser automatically implements the tagger, but we'll see later). While the software is very useful, it's written in Java--which is not quite as nice to play with as Python for a number of reasons (lacks NLP libraries, lower level language, etc). The problem then is finding a way to use a Java program like it's a Python program.<br><br>\n",
    "The two main options I looked into was a traditional import and a private server. One route of solving our problem is to use a traditional \"wrapper\" library/program. This program is essentially a translator between Java and Python. Unfortunately, the Stanford team itself doesn't actually make these wrappers (they would have to make them for a *lot* of languages). The existing wrappers--specifically the <u>stanfordcorenlp</u> library--weren't available through Anaconda (the platform through which we are running this exciting program right now), so I went another route.<br><br>\n",
    "The direction I chose was to host a server that runs the out-of-the-box Java program, and to access it through a Python API. This involves a small amount of command line setup, but it saves the trouble of changing environment variables or using directories in Python.<br><br>\n",
    "<a id='1_b'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How To Run A Server**<br>\n",
    "*Note*: Huge thanks to Khalid Alnajjar, linked his guide in resources.\n",
    "I've never actually hosted any sort of server before, so here's a quick summary:\n",
    "1. download and extract the CoreNLP somewhere.\n",
    "2. on the command line, cd into that directory\n",
    "    - *stanford-corenlp-full-2018-10-05* should be the folder\n",
    "3. run this command to host the server:\n",
    "    - java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse,sentiment\" -port 9000 -timeout 30000 \n",
    "4. pick up [here](#1_d)\n",
    "<a id='1_c'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**:<br>\n",
    "1. documentation for the parser: http://www.nltk.org/_modules/nltk/parse/stanford.html\n",
    "2. for more on running the server: https://www.khalidalnajjar.com/setup-use-stanford-corenlp-server-python/\n",
    "3. StanfordCoreNLP's GitHub page: https://github.com/stanfordnlp/CoreNLP\n",
    "\n",
    "<a id='1_d'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk import StanfordPOSTagger\n",
    "from nltk.parse import stanford\n",
    "from nltk.parse import CoreNLPParser\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds parser\n",
    "parser = CoreNLPParser(url='http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('ROOT', [Tree('S', [Tree('NP', [Tree('NP', [Tree('DT', ['The']), Tree('NNP', ['King'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NNP', ['France'])])])]), Tree('VP', [Tree('VBZ', ['is']), Tree('ADJP', [Tree('JJ', ['Bald'])])]), Tree('.', ['.'])])])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing parser on sentence\n",
    "list(parser.raw_parse('The King of France is Bald.'))\n",
    "#if you want to see the list of commands\n",
    "#dir(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_tree() missing 1 required positional argument: 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5340ed9129e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: make_tree() missing 1 required positional argument: 'result'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
